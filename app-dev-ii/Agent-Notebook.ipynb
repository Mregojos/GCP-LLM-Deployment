{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3802712c-05d2-44ff-b790-12e676a6e782",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multimodal Deployment\n",
    "\n",
    "Resource: ai.google.dev/doccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c333255-d54b-4cb7-b59e-c178b064fc5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform -q -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a07110-ec3f-4801-8e18-0474b9896876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b3f34-c927-411b-a192-df79d61fc7cc",
   "metadata": {},
   "source": [
    "## Chat Capable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9a4c2-7c31-40cb-a2d8-2ba5ddfb2db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mm_model = GenerativeModel(\"gemini-pro\")\n",
    "mm_chat = mm_model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52165b1b-88bd-4b2f-ade7-bfcfa51c20b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Jupyter\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e459ea0-291b-4c53-932a-22a346173c2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def start_chat(prompt):\n",
    "    start = t.time()\n",
    "    response = mm_chat.send_message(prompt)\n",
    "    display(Markdown(response.text))\n",
    "    end = t.time()\n",
    "    print(f\"Total Processing Time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08983ec-bf6c-4b66-a572-3fa988d7f256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def start_chat_stream(prompt):\n",
    "    start = t.time()\n",
    "    response_ = \"\"\n",
    "    response = mm_chat.send_message(prompt, stream=True)\n",
    "    for chunk in response:\n",
    "        print(chunk.text)\n",
    "        response_ = response_ + chunk.text \n",
    "    display(Markdown(response_))\n",
    "    end = t.time()\n",
    "    print(f\"Total Processing Time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e677e02e-3ef0-4ff7-8453-ae31a4943d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = input(\"Prompt\")\n",
    "stream = input(\"Stream: T or F\")\n",
    "if stream == \"T\":\n",
    "    start_chat_stream(prompt)\n",
    "elif stream == \"F\":\n",
    "    start_chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408a498-0936-4904-b421-a3ca88e14898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chat History\n",
    "mm_chat.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e8efe-95f6-47eb-97d7-03db0f8e9676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
